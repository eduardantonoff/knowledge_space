{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Glossary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Portions of this page are reproduced from work created and shared by Google and used according to terms described in the Creative Commons 4.0 Attribution License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Google for Developers](https://developers.google.com/terms/site-policies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing:\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# neo4j:\n",
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This glossary defines general machine learning terms, plus\n",
      "terms specific to TensorFlow.\n"
     ]
    }
   ],
   "source": [
    "# webpage\n",
    "url = 'https://developers.google.com/machine-learning/glossary'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# extracting a specific section by class name:\n",
    "section = soup.find('div', class_='devsite-article-body clearfix')\n",
    "\n",
    "text = section.get_text()\n",
    "print(text[1:90])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ablation', 'A/B testing', 'accelerator chip', 'accuracy', 'action']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = section.find_all('h2', class_='hide-from-toc')\n",
    "\n",
    "terms = []\n",
    "\n",
    "# extracting 'id' and 'data-text' attributes\n",
    "for header in headers:\n",
    "    header_id = header.get('id')\n",
    "    data_text = header.get('data-text')\n",
    "    terms.append(data_text.strip())  # Remove trailing spaces\n",
    "\n",
    "terms[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "597"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('terms.txt', 'w') as f:\n",
    "    for term in terms:\n",
    "        f.write(\"%s\\n\" % term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['batch normalization', 'normalization', 'Z-score normalization']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = 'normal'\n",
    "\n",
    "[term for term in terms if token in term]\n",
    "# [term for term in terms if term.startswith(token)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glossary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "glossary = {}\n",
    "\n",
    "# extracting 'id' and 'data-text' attributes\n",
    "for header in headers:\n",
    "    header_id = header.get('id')\n",
    "    data_text = header.get('data-text')\n",
    "    description = \"\"\n",
    "\n",
    "    # find all tags that come after the current header\n",
    "    next_tags = header.find_all_next()\n",
    "    for tag in next_tags:\n",
    "        # if we encounter another 'h2' tag, we've gone too far, so break the loop\n",
    "        if tag.name == 'h2':\n",
    "            break\n",
    "\n",
    "        # if we encounter a 'p' tag that does not contain a 'glossary-anchor', add its text to the description\n",
    "        if tag.name == 'p' and tag.get_text().strip() and not tag.find('a', class_='glossary-anchor'):\n",
    "            description += tag.get_text() + \" \"\n",
    "        \n",
    "        # if we encounter a 'ul' tag, add the text from each 'li' tag within it to the description\n",
    "        if tag.name == 'ul':\n",
    "            for li in tag.find_all('li'):\n",
    "                description += li.get_text() + \" \"\n",
    "\n",
    "    # add the description to the glossary under the current header\n",
    "    glossary[data_text] = description.strip()\n",
    "\n",
    "# convert the glossary into a DataFrame\n",
    "data = pd.DataFrame(list(glossary.items()), columns=['Term', 'Description'])\n",
    "\n",
    "# save the DataFrame as a CSV file\n",
    "data.to_csv('machine_learning_glossary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = os.getenv('NEO4J_URI')\n",
    "username = os.getenv('NEO4J_USERNAME')\n",
    "password = os.getenv('NEO4J_PASSWORD')\n",
    "database = os.getenv('NEO4J_DATABASE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### neo4j "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(uri, auth = ( username, password ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create nodes and relationships\n",
    "def create_graph(tx, term, description):\n",
    "    # create the node for the main term\n",
    "    tx.run(\"MERGE (t:Term {name: $term, description: $description})\", term=term, description=description)\n",
    "    \n",
    "    # find mentions of other terms in the description and create relationships\n",
    "    for other_term in data['Term']:\n",
    "        if other_term != term and other_term.lower() in description.lower():\n",
    "            tx.run(\"MATCH (t1:Term {name: $term}), (t2:Term {name: $other_term}) \"\n",
    "                   \"MERGE (t1)-[:MENTIONS]->(t2)\", term=term, other_term=other_term)\n",
    "\n",
    "# adding nodes and relationships to the graph\n",
    "with driver.session(database=database) as session:\n",
    "    for index, row in data.iterrows():\n",
    "        session.execute_write(create_graph, row['Term'], row['Description'])\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linear_regression_graph(driver):\n",
    "    with driver.session() as session:\n",
    "\n",
    "        # clear the graph\n",
    "        session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "        # create nodes and relationships\n",
    "        session.run(\"\"\"\n",
    "        CREATE\n",
    "        (ml:Concept {name: 'Machine Learning'}),\n",
    "        (coreConcepts:Concept {name: 'Core Concepts'}),\n",
    "        (modelTypes:Concept {name: 'Model Types'}),\n",
    "        (dataPrep:Concept {name: 'Data Preparation'}),\n",
    "        (featureEng:Concept {name: 'Feature Engineering'}),\n",
    "        (performanceEval:Concept {name: 'Performance Evaluation'}),\n",
    "        (optimization:Concept {name: 'Optimization Techniques'}),\n",
    "        (lr:Concept {name: 'Linear Regression'}),\n",
    "        (mse:Concept {name: 'Mean Squared Error'}),\n",
    "        (rmse:Concept {name: 'Root Mean Squared Error'}),\n",
    "        (sgd:Concept {name: 'Stochastic Gradient Descent'}),\n",
    "        (norm:Concept {name: 'Normalization'}),\n",
    "        (featSel:Concept {name: 'Feature Selection'}),\n",
    "        \n",
    "        (lr)-[:IS_A]->(modelTypes),\n",
    "        (modelTypes)-[:PART_OF]->(ml),\n",
    "        (sgd)-[:USED_FOR]->(lr),\n",
    "        (mse)-[:USED_IN]->(lr),\n",
    "        (rmse)-[:SPECIFIC_FORM]->(mse),\n",
    "        (dataPrep)-[:USED_IN]->(lr),\n",
    "        (norm)-[:IS_A]->(dataPrep),\n",
    "        (featSel)-[:IS_A]->(featureEng),\n",
    "        (featureEng)-[:PART_OF]->(dataPrep),\n",
    "        (performanceEval)-[:EVALUATES]->(lr),\n",
    "        (sgd)-[:DEPENDS_ON]->(mse),\n",
    "        (optimization)-[:ENCOMPASSES]->(sgd),\n",
    "        (optimization)-[:PART_OF]->(coreConcepts),\n",
    "        (coreConcepts)-[:PART_OF]->(ml)\n",
    "        \"\"\")\n",
    "\n",
    "# create the graph based on Linear Regression and related concepts as an example\n",
    "create_linear_regression_graph(driver)\n",
    "print(\"Linear Regression graph has been created.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
